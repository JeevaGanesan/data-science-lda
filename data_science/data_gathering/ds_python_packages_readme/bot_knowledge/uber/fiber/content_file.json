{"results": {"content_files": {"name": "README.md", "path": "README.md", "content": "<p align=\"right\">\n  <a href=\"https://travis-ci.com/uber/fiber\">\n      <img src=\"https://travis-ci.com/uber/fiber.svg?token=BxMzxQEDDtTBPG9151kk&branch=master\" alt=\"build\" />\n  </a>\n</p>\n\n<img src=\"docs/img/fiber_logo.png\" alt=\"drawing\" width=\"550\"/>\n\n[**Project Home**](https://uber.github.io/fiber/) &nbsp;\n[**Blog**](https://uber.github.io/fiber/introduction/) &nbsp;\n[**Documents**](https://uber.github.io/fiber/getting-started/) &nbsp;\n[**Paper**](https://arxiv.org/abs/2003.11164) &nbsp;\n[**Media Coverage**](https://venturebeat.com/2020/03/26/uber-details-fiber-a-framework-for-distributed-ai-model-training/)\n\n# Fiber\n\n### Distributed Computing for AI Made Simple\n\n*This project is experimental and the APIs are not considered stable.*\n\nFiber is a Python distributed computing library for modern computer clusters.\n\n* It is easy to use. Fiber allows you to write programs that run on a computer cluster level without the need to dive into the details of computer cluster.\n* It is easy to learn. Fiber provides the same API as Python's standard [multiprocessing](https://docs.python.org/3.6/library/multiprocessing.html) library that you are familiar with. If you know how to use multiprocessing, you can program a computer cluster with Fiber.\n* It is fast. Fiber's communication backbone is built on top of [Nanomsg](https://nanomsg.org/) which is a high-performance asynchronous messaging library to allow fast and reliable communication.\n* It doesn't need deployment. You run it as the same way as running a normal application on a computer cluster and Fiber handles the rest for you.\n* It it reliable. Fiber has built-in error handling when you are running a pool of workers. Users can focus on writing the actual application code instead of dealing with crashed workers.\n\nOriginally, it was developed to power large scale parallel scientific computation projects like [POET](https://eng.uber.com/poet-open-ended-deep-learning/) and it has been used to power similar projects within Uber.\n\n\n## Installation\n\n```\npip install fiber\n```\n\nCheck [here](https://uber.github.io/fiber/installation/) for details.\n\n## Quick Start\n\n\n### Hello Fiber\nTo use Fiber, simply import it in your code and it works very similar to multiprocessing.\n\n```python\nimport fiber\n\nif __name__ == '__main__':\n    fiber.Process(target=print, args=('Hello, Fiber!',)).start()\n```\n\nNote that `if __name__ == '__main__':` is necessary because Fiber uses *spawn* method to start new processes. Check [here](https://stackoverflow.com/questions/50781216/in-python-multiprocessing-process-do-we-have-to-use-name-main) for details.\n\nLet's take look at another more complex example:\n\n### Estimating Pi\n\n\n```python\nimport fiber\nimport random\n\n@fiber.meta(cpu=1)\ndef inside(p):\n    x, y = random.random(), random.random()\n    return x * x + y * y < 1\n\ndef main():\n    NUM_SAMPLES = int(1e6)\n    pool = fiber.Pool(processes=4)\n    count = sum(pool.map(inside, range(0, NUM_SAMPLES)))\n    print(\"Pi is roughly {}\".format(4.0 * count / NUM_SAMPLES))\n\nif __name__ == '__main__':\n    main()\n```\n\n\nFiber implements most of multiprocessing's API including `Process`, `SimpleQueue`, `Pool`, `Pipe`, `Manager` and it has its own extension to the multiprocessing's API to make it easy to compose large scale distributed applications. For the detailed API guild, check out [here](https://uber.github.io/fiber/process/).\n\n### Running on a Kubernetes cluster\n\nFiber also has native support for computer clusters. To run the above example on Kubernetes, fiber provided a convenient command line tool to manage the workflow.\n\nAssume you have a working docker environment locally and have finished configuring [Google Cloud SDK](https://cloud.google.com/sdk/docs/quickstarts). Both `gcloud` and `kubectl` are available locally. Then you can start by writing a Dockerfile which describes the running environment.  An example Dockerfile looks like this:\n\n```dockerfile\n# example.docker\nFROM python:3.6-buster\nADD examples/pi_estimation.py /root/pi_estimation.py\nRUN pip install fiber\n```\n**Build an image and launch your job**\n\n```\nfiber run -a python3 /root/pi_estimation.py\n```\n\nThis command will look for local Dockerfile and build a docker image and push it to your Google Container Registry . It then launches the main job which contains your code and runs the command `python3 /root/pi_estimation.py` inside your job. Once the main job is running, it will start 4 subsequent jobs on the cluster and each of them is a Pool worker.\n\n\n## Supported platforms\n\n* Operating system: Linux\n* Python: 3.6+\n* Supported cluster management systems:\n\t* Kubernetes (Tested with Google Kubernetes Engine on Google cloud)\n\nWe are interested in supporting other cluster management systems like [Slurm](https://slurm.schedmd.com/), if you want to contribute to it please let us know.\n\n\nCheck [here](https://uber.github.io/fiber/platforms/) for details.\n\n## Documentation\n\nThe documentation, including method/API references, can be found [here](https://uber.github.io/fiber/getting-started/).\n\n\n## Testing\n\nInstall test dependencies. You'll also need to make sure [docker](https://docs.docker.com/install/) is available on the testing machine.\n\n```bash\n$ pip install -e .[test]\n```\n\nRun tests\n\n```bash\n$ make test\n```\n\n## Contributing\nPlease read our [code of conduct](CODE_OF_CONDUCT.md) before you contribute! You can find details for submitting pull requests in the [CONTRIBUTING.md](CONTRIBUTING.md) file. Issue [template](https://help.github.com/articles/about-issue-and-pull-request-templates/).\n\n## Versioning\nWe document versions and changes in our changelog - see the [CHANGELOG.md](CHANGELOG.md) file for details.\n\n## License\nThis project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.\n\n## Cite Fiber\n\n```\n@misc{zhi2020fiber,\n    title={Fiber: A Platform for Efficient Development and Distributed Training for Reinforcement Learning and Population-Based Methods},\n    author={Jiale Zhi and Rui Wang and Jeff Clune and Kenneth O. Stanley},\n    year={2020},\n    eprint={2003.11164},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG}\n}\n```\n\n## Acknowledgments\n* Special thanks to Piero Molino for designing the logo for Fiber\n"}}}