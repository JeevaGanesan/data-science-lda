{"results": {"content_files": {"name": "README.rst", "path": "README.rst", "content": ".. image:: https://github.com/ray-project/ray/raw/master/doc/source/images/ray_header_logo.png\n\n.. image:: https://travis-ci.com/ray-project/ray.svg?branch=master\n    :target: https://travis-ci.com/ray-project/ray\n\n.. image:: https://readthedocs.org/projects/ray/badge/?version=latest\n    :target: http://docs.ray.io/en/latest/?badge=latest\n\n|\n\n\n**Ray is a fast and simple framework for building and running distributed applications.**\n\nRay is packaged with the following libraries for accelerating machine learning workloads:\n\n- `Tune`_: Scalable Hyperparameter Tuning\n- `RLlib`_: Scalable Reinforcement Learning\n- `RaySGD <https://docs.ray.io/en/latest/raysgd/raysgd.html>`__: Distributed Training Wrappers\n\nInstall Ray with: ``pip install ray``. For nightly wheels, see the\n`Installation page <https://docs.ray.io/en/latest/installation.html>`__.\n\n**NOTE:** `We are deprecating Python 2 support soon.`_\n\n.. _`We are deprecating Python 2 support soon.`: https://github.com/ray-project/ray/issues/6580\n\nQuick Start\n-----------\n\nExecute Python functions in parallel.\n\n.. code-block:: python\n\n    import ray\n    ray.init()\n\n    @ray.remote\n    def f(x):\n        return x * x\n\n    futures = [f.remote(i) for i in range(4)]\n    print(ray.get(futures))\n\nTo use Ray's actor model:\n\n.. code-block:: python\n\n\n    import ray\n    ray.init()\n\n    @ray.remote\n    class Counter(object):\n        def __init__(self):\n            self.n = 0\n\n        def increment(self):\n            self.n += 1\n\n        def read(self):\n            return self.n\n\n    counters = [Counter.remote() for i in range(4)]\n    [c.increment.remote() for c in counters]\n    futures = [c.read.remote() for c in counters]\n    print(ray.get(futures))\n\n\nRay programs can run on a single machine, and can also seamlessly scale to large clusters. To execute the above Ray script in the cloud, just download `this configuration file <https://github.com/ray-project/ray/blob/master/python/ray/autoscaler/aws/example-full.yaml>`__, and run:\n\n``ray submit [CLUSTER.YAML] example.py --start``\n\nRead more about `launching clusters <https://docs.ray.io/en/latest/autoscaling.html>`_.\n\nTune Quick Start\n----------------\n\n.. image:: https://github.com/ray-project/ray/raw/master/doc/source/images/tune-wide.png\n\n`Tune`_ is a library for hyperparameter tuning at any scale.\n\n- Launch a multi-node distributed hyperparameter sweep in less than 10 lines of code.\n- Supports any deep learning framework, including PyTorch, TensorFlow, and Keras.\n- Visualize results with `TensorBoard <https://www.tensorflow.org/get_started/summaries_and_tensorboard>`__.\n- Choose among scalable SOTA algorithms such as `Population Based Training (PBT)`_, `Vizier's Median Stopping Rule`_, `HyperBand/ASHA`_.\n- Tune integrates with many optimization libraries such as `Facebook Ax <http://ax.dev>`_, `HyperOpt <https://github.com/hyperopt/hyperopt>`_, and `Bayesian Optimization <https://github.com/fmfn/BayesianOptimization>`_ and enables you to scale them transparently.\n\nTo run this example, you will need to install the following:\n\n.. code-block:: bash\n\n    $ pip install ray[tune] torch torchvision filelock\n\n\nThis example runs a parallel grid search to train a Convolutional Neural Network using PyTorch.\n\n.. code-block:: python\n\n\n    import torch.optim as optim\n    from ray import tune\n    from ray.tune.examples.mnist_pytorch import (\n        get_data_loaders, ConvNet, train, test)\n\n\n    def train_mnist(config):\n        train_loader, test_loader = get_data_loaders()\n        model = ConvNet()\n        optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"])\n        for i in range(10):\n            train(model, optimizer, train_loader)\n            acc = test(model, test_loader)\n            tune.track.log(mean_accuracy=acc)\n\n\n    analysis = tune.run(\n        train_mnist, config={\"lr\": tune.grid_search([0.001, 0.01, 0.1])})\n\n    print(\"Best config: \", analysis.get_best_config(metric=\"mean_accuracy\"))\n\n    # Get a dataframe for analyzing trial results.\n    df = analysis.dataframe()\n\nIf TensorBoard is installed, automatically visualize all trial results:\n\n.. code-block:: bash\n\n    tensorboard --logdir ~/ray_results\n\n.. _`Tune`: https://docs.ray.io/en/latest/tune.html\n.. _`Population Based Training (PBT)`: https://docs.ray.io/en/latest/tune-schedulers.html#population-based-training-pbt\n.. _`Vizier's Median Stopping Rule`: https://docs.ray.io/en/latest/tune-schedulers.html#median-stopping-rule\n.. _`HyperBand/ASHA`: https://docs.ray.io/en/latest/tune-schedulers.html#asynchronous-hyperband\n\nRLlib Quick Start\n-----------------\n\n.. image:: https://github.com/ray-project/ray/raw/master/doc/source/images/rllib-wide.jpg\n\n`RLlib`_ is an open-source library for reinforcement learning built on top of Ray that offers both high scalability and a unified API for a variety of applications.\n\n.. code-block:: bash\n\n  pip install tensorflow  # or tensorflow-gpu\n  pip install ray[rllib]  # also recommended: ray[debug]\n\n.. code-block:: python\n\n    import gym\n    from gym.spaces import Discrete, Box\n    from ray import tune\n\n    class SimpleCorridor(gym.Env):\n        def __init__(self, config):\n            self.end_pos = config[\"corridor_length\"]\n            self.cur_pos = 0\n            self.action_space = Discrete(2)\n            self.observation_space = Box(0.0, self.end_pos, shape=(1, ))\n\n        def reset(self):\n            self.cur_pos = 0\n            return [self.cur_pos]\n\n        def step(self, action):\n            if action == 0 and self.cur_pos > 0:\n                self.cur_pos -= 1\n            elif action == 1:\n                self.cur_pos += 1\n            done = self.cur_pos >= self.end_pos\n            return [self.cur_pos], 1 if done else 0, done, {}\n\n    tune.run(\n        \"PPO\",\n        config={\n            \"env\": SimpleCorridor,\n            \"num_workers\": 4,\n            \"env_config\": {\"corridor_length\": 5}})\n\n.. _`RLlib`: https://docs.ray.io/en/latest/rllib.html\n\n\nMore Information\n----------------\n\n- `Documentation`_\n- `Tutorial`_\n- `Blog`_\n- `Ray paper`_\n- `Ray HotOS paper`_\n- `RLlib paper`_\n- `Tune paper`_\n\n.. _`Documentation`: http://docs.ray.io/en/latest/index.html\n.. _`Tutorial`: https://github.com/ray-project/tutorial\n.. _`Blog`: https://ray-project.github.io/\n.. _`Ray paper`: https://arxiv.org/abs/1712.05889\n.. _`Ray HotOS paper`: https://arxiv.org/abs/1703.03924\n.. _`RLlib paper`: https://arxiv.org/abs/1712.09381\n.. _`Tune paper`: https://arxiv.org/abs/1807.05118\n\nGetting Involved\n----------------\n\n- `ray-dev@googlegroups.com`_: For discussions about development or any general\n  questions.\n- `StackOverflow`_: For questions about how to use Ray.\n- `GitHub Issues`_: For reporting bugs and feature requests.\n- `Pull Requests`_: For submitting code contributions.\n- `Meetup Group`_: Join our meetup group.\n- `Community Slack`_: Join our Slack workspace.\n- `Twitter`_: Follow updates on Twitter.\n\n.. _`ray-dev@googlegroups.com`: https://groups.google.com/forum/#!forum/ray-dev\n.. _`GitHub Issues`: https://github.com/ray-project/ray/issues\n.. _`StackOverflow`: https://stackoverflow.com/questions/tagged/ray\n.. _`Pull Requests`: https://github.com/ray-project/ray/pulls\n.. _`Meetup Group`: https://www.meetup.com/Bay-Area-Ray-Meetup/\n.. _`Community Slack`: https://forms.gle/9TSdDYUgxYs8SA9e8\n.. _`Twitter`: https://twitter.com/raydistributed\n"}}}